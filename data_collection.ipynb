{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yingchenjin/IANAL/blob/main/data_collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eIku0KYkgrS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d02fcae-fea0-4976-dec1-ff6ab22592d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing questions that contain IANAL...\n",
            "Error: Received status code 403\n",
            "Response Text: <!DOCTYPE html><html lang=\"en-US\"><head><title>Just a moment...</title><meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"><meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\"><meta name=\"robots\" content=\"noindex,nofollow\"><meta name=\"viewport\" content=\"width=device-width,initial-scale=1\"><style>*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131;font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetic\n",
            "No more question items or an error occurred.\n",
            "Processing answers that contain IANAL...\n",
            "Error: Received status code 403\n",
            "Response Text: <!DOCTYPE html><html lang=\"en-US\"><head><title>Just a moment...</title><meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"><meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\"><meta name=\"robots\" content=\"noindex,nofollow\"><meta name=\"viewport\" content=\"width=device-width,initial-scale=1\"><style>*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131;font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetic\n",
            "No more excerpt items or an error occurred.\n",
            "Data saved to ianal_posts.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import csv\n",
        "import time\n",
        "\n",
        "\"\"\"\n",
        "Script used to find entries of Stack Exchange sites that contain the acronym \"IANAL\" and\n",
        "save them to a CSV file. The script will search for questions and answers containing \"IANAL\"\n",
        "before saving the data.\n",
        "\"\"\"\n",
        "\n",
        "# Configuration\n",
        "SITE = 'softwareengineering'  # Change to another Stack Exchange site as needed\n",
        "OUTPUT_FILE = 'ianal_posts.csv'\n",
        "API_KEY = 'rl_mQJm8BgRoQ5o9oj8igSfNR66y'  # Add your API key here for higher rate limits (optional)\n",
        "\n",
        "# API endpoints\n",
        "QUESTION_SEARCH_URL = \"https://api.stackexchange.com/2.3/search/advanced\"\n",
        "QUESTION_ANSWERS_URL = \"https://api.stackexchange.com/2.3/questions/{id}/answers\"\n",
        "ANSWER_DETAIL_URL = \"https://api.stackexchange.com/2.3/answers/{id}\"\n",
        "QUESTION_DETAIL_URL = \"https://api.stackexchange.com/2.3/questions/{id}\"\n",
        "EXCERPT_SEARCH_URL = \"https://api.stackexchange.com/2.3/search/excerpts\"\n",
        "\n",
        "# Track processed answer IDs to avoid duplicates\n",
        "processed_answer_ids = set()\n",
        "\n",
        "# Function to safely make API requests with error handling\n",
        "def make_request(url, params):\n",
        "    \"\"\"Helper function to make API requests with retries and error handling.\"\"\"\n",
        "    for _ in range(3):  # Retry up to 3 times in case of failure\n",
        "        try:\n",
        "            response = requests.get(url, params=params)\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "            elif response.status_code == 429:\n",
        "                print(\"Rate limit exceeded. Waiting before retrying...\")\n",
        "                time.sleep(5)  # Wait longer for rate limits\n",
        "            else:\n",
        "                print(f\"Error: Received status code {response.status_code}\")\n",
        "                print(\"Response Text:\", response.text[:500])\n",
        "                return None\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Request failed: {e}\")\n",
        "            time.sleep(2)  # Short wait before retrying\n",
        "    return None\n",
        "\n",
        "# Open the CSV file for writing\n",
        "with open(OUTPUT_FILE, mode='w', newline='', encoding='utf-8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    # CSV header row\n",
        "    writer.writerow([\"post_type\", \"post_id\", \"creation_date\", \"question_id\", \"question_title\", \"question_body\", \"answer_body\"])\n",
        "\n",
        "    ###########################################################################\n",
        "    # PART 1: Process questions that contain \"IANAL\" using /search/advanced\n",
        "    ###########################################################################\n",
        "    print(\"Processing questions that contain IANAL...\")\n",
        "    page = 1\n",
        "    while True:\n",
        "        params = {\n",
        "            'q': 'IANAL',\n",
        "            'site': SITE,\n",
        "            'pagesize': 100,\n",
        "            'page': page,\n",
        "            'filter': 'withbody',\n",
        "            'key': API_KEY  # Use API key if available\n",
        "        }\n",
        "        data = make_request(QUESTION_SEARCH_URL, params)\n",
        "        if not data or 'items' not in data:\n",
        "            print(\"No more question items or an error occurred.\")\n",
        "            break\n",
        "\n",
        "        items = data.get('items', [])\n",
        "        print(f\"Page {page} | Returned Items: {len(items)} | Has More: {data.get('has_more')}\")\n",
        "\n",
        "        for question in items:\n",
        "            if \"ianal\" in question.get('body', '').lower():\n",
        "                question_id = question.get('question_id')\n",
        "                creation_date = question.get('creation_date')\n",
        "                title = question.get('title')\n",
        "                question_body = question.get('body')\n",
        "\n",
        "                # Write question row\n",
        "                writer.writerow([\"question\", question_id, creation_date, question_id, title, question_body, \"\"])\n",
        "\n",
        "                # Fetch answers\n",
        "                ans_params = {'site': SITE, 'pagesize': 100, 'filter': 'withbody', 'key': API_KEY}\n",
        "                ans_data = make_request(QUESTION_ANSWERS_URL.format(id=question_id), ans_params)\n",
        "\n",
        "                # Process answers\n",
        "                if ans_data and 'items' in ans_data:\n",
        "                    for answer in ans_data['items']:\n",
        "                        answer_body = answer.get('body', '')\n",
        "                        if \"ianal\" in answer_body.lower():\n",
        "                            answer_id = answer.get('answer_id')\n",
        "                            creation_date_ans = answer.get('creation_date')\n",
        "                            if answer_id not in processed_answer_ids:\n",
        "                                writer.writerow([\"answer\", answer_id, creation_date_ans, question_id, title, question_body, answer_body])\n",
        "                                processed_answer_ids.add(answer_id)\n",
        "\n",
        "                time.sleep(0.2)  # Pause to respect API limits\n",
        "\n",
        "        if not data.get('has_more'):\n",
        "            break\n",
        "\n",
        "        page += 1\n",
        "        time.sleep(1)  # Slight delay to avoid hitting rate limits\n",
        "\n",
        "    ##################################################################################\n",
        "    # PART 2: Process answers that contain IANAL (but whose parent question did not)\n",
        "    ##################################################################################\n",
        "    print(\"Processing answers that contain IANAL...\")\n",
        "    page = 1\n",
        "    while True:\n",
        "        params = {'q': 'IANAL', 'site': SITE, 'pagesize': 100, 'page': page, 'key': API_KEY}\n",
        "        data = make_request(EXCERPT_SEARCH_URL, params)\n",
        "        if not data or 'items' not in data:\n",
        "            print(\"No more excerpt items or an error occurred.\")\n",
        "            break\n",
        "\n",
        "        items = data.get('items', [])\n",
        "        print(f\"Page {page} | Returned Items: {len(items)} | Has More: {data.get('has_more')}\")\n",
        "\n",
        "        for item in items:\n",
        "            if item.get('item_type') == 'answer':\n",
        "                answer_id = item.get('answer_id')\n",
        "                if answer_id in processed_answer_ids or answer_id is None:\n",
        "                    continue\n",
        "\n",
        "                # Fetch full answer details\n",
        "                ans_params = {'site': SITE, 'filter': 'withbody', 'key': API_KEY}\n",
        "                ans_data = make_request(ANSWER_DETAIL_URL.format(id=answer_id), ans_params)\n",
        "                if not ans_data or 'items' not in ans_data:\n",
        "                    continue\n",
        "\n",
        "                answer_detail = ans_data['items'][0]\n",
        "                answer_body = answer_detail.get('body', '')\n",
        "                if \"ianal\" not in answer_body.lower():\n",
        "                    continue\n",
        "\n",
        "                creation_date_ans = answer_detail.get('creation_date')\n",
        "                question_id = answer_detail.get('question_id')\n",
        "\n",
        "                # Fetch parent question details\n",
        "                quest_params = {'site': SITE, 'filter': 'withbody', 'key': API_KEY}\n",
        "                quest_data = make_request(QUESTION_DETAIL_URL.format(id=question_id), quest_params)\n",
        "                if not quest_data or 'items' not in quest_data:\n",
        "                    continue\n",
        "\n",
        "                question_detail = quest_data['items'][0]\n",
        "                title = question_detail.get('title')\n",
        "                question_body = question_detail.get('body')\n",
        "\n",
        "                # Write row for answer and parent question\n",
        "                writer.writerow([\"answer\", answer_id, creation_date_ans, question_id, title, question_body, answer_body])\n",
        "                processed_answer_ids.add(answer_id)\n",
        "\n",
        "                time.sleep(0.2)  # Pause to respect API limits\n",
        "\n",
        "        if not data.get('has_more'):\n",
        "            break\n",
        "\n",
        "        page += 1\n",
        "        time.sleep(1)  # Slight delay to avoid hitting rate limits\n",
        "\n",
        "print(f\"Data saved to {OUTPUT_FILE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "import time\n",
        "\n",
        "\"\"\"\n",
        "Script used to find entries of Stack Exchange sites that contain the acronym \"IANAL\" and\n",
        "retrieve all answers for those questions, along with upvotes and number of answers per question.\n",
        "\"\"\"\n",
        "\n",
        "# Configuration\n",
        "SITE = 'softwareengineering'  # Change to another Stack Exchange site as needed\n",
        "OUTPUT_FILE = 'ianal_posts.csv'\n",
        "API_KEY = 'rl_gkMMYsnHwp1tyui3hWdjFRN5U'  # Add your API key here for higher rate limits (optional)\n",
        "\n",
        "# API endpoints\n",
        "ANSWER_SEARCH_URL = \"https://api.stackexchange.com/2.3/search/excerpts\"\n",
        "QUESTION_ANSWERS_URL = \"https://api.stackexchange.com/2.3/questions/{id}/answers\"\n",
        "QUESTION_DETAIL_URL = \"https://api.stackexchange.com/2.3/questions/{id}\"\n",
        "\n",
        "def make_request(url, params):\n",
        "    \"\"\"Helper function to make API requests with retries and error handling.\"\"\"\n",
        "    for _ in range(3):  # Retry up to 3 times in case of failure\n",
        "        try:\n",
        "            response = requests.get(url, params=params)\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "            elif response.status_code == 429:\n",
        "                print(\"Rate limit exceeded. Waiting before retrying...\")\n",
        "                time.sleep(5)\n",
        "            else:\n",
        "                print(f\"Error: Received status code {response.status_code}\")\n",
        "                return None\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Request failed: {e}\")\n",
        "            time.sleep(2)\n",
        "    return None\n",
        "\n",
        "with open(OUTPUT_FILE, mode='w', newline='', encoding='utf-8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"question_id\", \"question_title\", \"question_body\", \"num_answers\", \"answers_with_upvotes\"])\n",
        "\n",
        "    print(\"Searching for answers that explicitly contain 'IANAL'...\")\n",
        "    page = 1\n",
        "    while True:\n",
        "        params = {\n",
        "            'q': 'IANAL',\n",
        "            'site': SITE,\n",
        "            'pagesize': 100,\n",
        "            'page': page,\n",
        "            'filter': 'withbody',\n",
        "            'item_type': 'answer',\n",
        "            'key': API_KEY\n",
        "        }\n",
        "        data = make_request(ANSWER_SEARCH_URL, params)\n",
        "        if not data or 'items' not in data:\n",
        "            break\n",
        "\n",
        "        question_ids = set()\n",
        "        for item in data.get('items', []):\n",
        "            if item.get('item_type') == 'answer':\n",
        "                question_ids.add(item.get('question_id'))\n",
        "\n",
        "        for question_id in question_ids:\n",
        "            # Fetch question details\n",
        "            quest_params = {'site': SITE, 'filter': 'withbody', 'key': API_KEY}\n",
        "            quest_data = make_request(QUESTION_DETAIL_URL.format(id=question_id), quest_params)\n",
        "\n",
        "            # Fetch all answers for the question\n",
        "            ans_params = {'site': SITE, 'pagesize': 100, 'filter': 'withbody', 'key': API_KEY}\n",
        "            ans_data = make_request(QUESTION_ANSWERS_URL.format(id=question_id), ans_params)\n",
        "\n",
        "            if not quest_data or 'items' not in quest_data or not ans_data or 'items' not in ans_data:\n",
        "                continue\n",
        "\n",
        "            question_detail = quest_data['items'][0]\n",
        "            question_title = question_detail.get('title', '')\n",
        "            question_body = question_detail.get('body', '')\n",
        "            num_answers = len(ans_data['items'])\n",
        "\n",
        "            # Store all answers and their upvotes in a structured format\n",
        "            answers_with_upvotes = []\n",
        "            for answer in ans_data['items']:\n",
        "                answer_id = answer.get('answer_id')\n",
        "                answer_body = answer.get('body', '').replace('\\n', ' ').replace('\\r', ' ')\n",
        "                upvotes = answer.get('score', 0)\n",
        "                answers_with_upvotes.append(f\"[Answer ID: {answer_id}, Upvotes: {upvotes}] {answer_body}\")\n",
        "\n",
        "            writer.writerow([question_id, question_title, question_body, num_answers, \" | \".join(answers_with_upvotes)])\n",
        "\n",
        "            time.sleep(0.2)\n",
        "\n",
        "        if not data.get('has_more'):\n",
        "            break\n",
        "\n",
        "        page += 1\n",
        "        time.sleep(1)\n",
        "\n",
        "print(f\"Data saved to {OUTPUT_FILE}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5RbfNb5M2Mo",
        "outputId": "4b754efc-0f46-45b3-bff2-9be0659fefc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for answers that explicitly contain 'IANAL'...\n",
            "Error: Received status code 403\n",
            "Data saved to ianal_posts.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "import time\n",
        "\n",
        "\"\"\"\n",
        "Script used to find entries of Stack Exchange sites that contain the acronym \"IANAL\" and\n",
        "retrieve all answers for those questions, along with upvotes and number of answers per question.\n",
        "\"\"\"\n",
        "\n",
        "# Configuration\n",
        "SITE = 'opensource'  # Change to another Stack Exchange site as needed\n",
        "OUTPUT_FILE = 'uvoss.csv'\n",
        "API_KEY = 'rl_HzTM85avzXjeFbbNQArcyrx67'  # Add your API key here for higher rate limits (optional)\n",
        "\n",
        "# API endpoints\n",
        "ANSWER_SEARCH_URL = \"https://api.stackexchange.com/2.3/search/excerpts\"\n",
        "QUESTION_ANSWERS_URL = \"https://api.stackexchange.com/2.3/questions/{id}/answers\"\n",
        "QUESTION_DETAIL_URL = \"https://api.stackexchange.com/2.3/questions/{id}\"\n",
        "\n",
        "def make_request(url, params):\n",
        "    \"\"\"Helper function to make API requests with retries and error handling.\"\"\"\n",
        "    for _ in range(3):  # Retry up to 3 times in case of failure\n",
        "        try:\n",
        "            response = requests.get(url, params=params)\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "            elif response.status_code == 429:\n",
        "                print(\"Rate limit exceeded. Waiting before retrying...\")\n",
        "                time.sleep(5)\n",
        "            else:\n",
        "                print(f\"Error: Received status code {response.status_code}\")\n",
        "                return None\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Request failed: {e}\")\n",
        "            time.sleep(2)\n",
        "    return None\n",
        "\n",
        "with open(OUTPUT_FILE, mode='w', newline='', encoding='utf-8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"question_id\", \"question_title\", \"question_body\", \"num_answers\", \"answers_with_upvotes\", \"majority\"])\n",
        "\n",
        "    print(\"Searching for answers that explicitly contain 'IANAL'...\")\n",
        "    page = 1\n",
        "    while True:\n",
        "        params = {\n",
        "            'q': 'IANAL',\n",
        "            'site': SITE,\n",
        "            'pagesize': 100,\n",
        "            'page': page,\n",
        "            'filter': 'withbody',\n",
        "            'item_type': 'answer',\n",
        "            'key': API_KEY\n",
        "        }\n",
        "        data = make_request(ANSWER_SEARCH_URL, params)\n",
        "        if not data or 'items' not in data:\n",
        "            break\n",
        "\n",
        "        question_ids = set()\n",
        "        for item in data.get('items', []):\n",
        "            if item.get('item_type') == 'answer':\n",
        "                question_ids.add(item.get('question_id'))\n",
        "\n",
        "        for question_id in question_ids:\n",
        "            # Fetch question details\n",
        "            quest_params = {'site': SITE, 'filter': 'withbody', 'key': API_KEY}\n",
        "            quest_data = make_request(QUESTION_DETAIL_URL.format(id=question_id), quest_params)\n",
        "\n",
        "            # Fetch all answers for the question\n",
        "            ans_params = {'site': SITE, 'pagesize': 100, 'filter': 'withbody', 'key': API_KEY}\n",
        "            ans_data = make_request(QUESTION_ANSWERS_URL.format(id=question_id), ans_params)\n",
        "\n",
        "            if not quest_data or 'items' not in quest_data or not ans_data or 'items' not in ans_data:\n",
        "                continue\n",
        "\n",
        "            question_detail = quest_data['items'][0]\n",
        "            question_title = question_detail.get('title', '')\n",
        "            question_body = question_detail.get('body', '')\n",
        "            num_answers = len(ans_data['items'])\n",
        "\n",
        "            # Store all answers and their upvotes in a structured format\n",
        "            answers_with_upvotes = []\n",
        "            max_upvotes = 0\n",
        "            ianal_answer_max = False\n",
        "            ianal_present = False\n",
        "\n",
        "            for answer in ans_data['items']:\n",
        "                answer_id = answer.get('answer_id')\n",
        "                answer_body = answer.get('body', '').replace('\\n', ' ').replace('\\r', ' ')\n",
        "                upvotes = answer.get('score', 0)\n",
        "                answers_with_upvotes.append(f\"[Answer ID: {answer_id}, Upvotes: {upvotes}] {answer_body}\")\n",
        "\n",
        "                # Determine max upvoted answer\n",
        "                if upvotes > max_upvotes:\n",
        "                    max_upvotes = upvotes\n",
        "                    ianal_answer_max = \"ianal\" in answer_body.lower()\n",
        "\n",
        "                if \"ianal\" in answer_body.lower():\n",
        "                    ianal_present = True\n",
        "\n",
        "            # Determine majority field\n",
        "            if num_answers == 1:\n",
        "                majority = \"NA\"\n",
        "            else:\n",
        "                majority = \"True\" if ianal_present and ianal_answer_max else \"False\"\n",
        "\n",
        "            writer.writerow([question_id, question_title, question_body, num_answers, \" | \".join(answers_with_upvotes), majority])\n",
        "\n",
        "            time.sleep(0.2)\n",
        "\n",
        "        if not data.get('has_more'):\n",
        "            break\n",
        "\n",
        "        page += 1\n",
        "        time.sleep(1)\n",
        "\n",
        "print(f\"Data saved to {OUTPUT_FILE}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izEGdngIZ2ko",
        "outputId": "5282a04b-2093-402e-e64a-15e93209a55e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for answers that explicitly contain 'IANAL'...\n",
            "Error: Received status code 403\n",
            "Data saved to uvoss.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset (Replace with your actual file path if running locally)\n",
        "file_path = \"ianal_posts_oss.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Check if the column exists\n",
        "if \"majority\" in df.columns:  # Adjust column name if needed\n",
        "    # Count occurrences of True, False, and NA values\n",
        "    true_count = (df[\"majority\"] == True).sum()\n",
        "    false_count = (df[\"majority\"] == False).sum()\n",
        "    na_count = df[\"majority\"].isna().sum()  # If NA values exist\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"True Count: {true_count}\")\n",
        "    print(f\"False Count: {false_count}\")\n",
        "    print(f\"NA Count: {na_count}\")\n",
        "\n",
        "else:\n",
        "    print(\"Column 'upvote_comparison' not found in dataset. Please check the column names.\")\n"
      ],
      "metadata": {
        "id": "1k-u97XbONi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cac4508-0a29-4297-c880-cbf8dceca018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Count: 42\n",
            "False Count: 52\n",
            "NA Count: 131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "import time\n",
        "\n",
        "\"\"\"\n",
        "Script used to find entries of Stack Exchange sites that contain the acronym \"IANAL\" and\n",
        "retrieve all answers for those questions, along with upvotes and number of answers per question.\n",
        "\"\"\"\n",
        "\n",
        "# Configuration\n",
        "SITE = 'serverfault'  # Change to another Stack Exchange site as needed\n",
        "OUTPUT_FILE = 'ianal_posts_server.csv'\n",
        "API_KEY = 'rl_HzTM85avzXjeFbbNQArcyrx67'  # Add your API key here for higher rate limits (optional)\n",
        "\n",
        "# API endpoints\n",
        "ANSWER_SEARCH_URL = \"https://api.stackexchange.com/2.3/search/excerpts\"\n",
        "QUESTION_ANSWERS_URL = \"https://api.stackexchange.com/2.3/questions/{id}/answers\"\n",
        "QUESTION_DETAIL_URL = \"https://api.stackexchange.com/2.3/questions/{id}\"\n",
        "\n",
        "def make_request(url, params):\n",
        "    \"\"\"Helper function to make API requests with retries and error handling.\"\"\"\n",
        "    for _ in range(3):  # Retry up to 3 times in case of failure\n",
        "        try:\n",
        "            response = requests.get(url, params=params)\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "            elif response.status_code == 429:\n",
        "                print(\"Rate limit exceeded. Waiting before retrying...\")\n",
        "                time.sleep(5)\n",
        "            else:\n",
        "                print(f\"Error: Received status code {response.status_code}\")\n",
        "                return None\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Request failed: {e}\")\n",
        "            time.sleep(2)\n",
        "    return None\n",
        "\n",
        "with open(OUTPUT_FILE, mode='w', newline='', encoding='utf-8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"question_id\", \"question_title\", \"question_body\", \"num_answers\", \"answers_with_upvotes\", \"majority\"])\n",
        "\n",
        "    print(\"Searching for answers that explicitly contain 'IANAL'...\")\n",
        "    page = 1\n",
        "    while True:\n",
        "        params = {\n",
        "            'q': 'IANAL',\n",
        "            'site': SITE,\n",
        "            'pagesize': 100,\n",
        "            'page': page,\n",
        "            'filter': 'withbody',\n",
        "            'item_type': 'answer',\n",
        "            'key': API_KEY\n",
        "        }\n",
        "        data = make_request(ANSWER_SEARCH_URL, params)\n",
        "        if not data or 'items' not in data:\n",
        "            break\n",
        "\n",
        "        question_ids = set()\n",
        "        for item in data.get('items', []):\n",
        "            if item.get('item_type') == 'answer':\n",
        "                question_ids.add(item.get('question_id'))\n",
        "\n",
        "        for question_id in question_ids:\n",
        "            # Fetch question details\n",
        "            quest_params = {'site': SITE, 'filter': 'withbody', 'key': API_KEY}\n",
        "            quest_data = make_request(QUESTION_DETAIL_URL.format(id=question_id), quest_params)\n",
        "\n",
        "            # Fetch all answers for the question\n",
        "            ans_params = {'site': SITE, 'pagesize': 100, 'filter': 'withbody', 'key': API_KEY}\n",
        "            ans_data = make_request(QUESTION_ANSWERS_URL.format(id=question_id), ans_params)\n",
        "\n",
        "            if not quest_data or 'items' not in quest_data or not ans_data or 'items' not in ans_data:\n",
        "                continue\n",
        "\n",
        "            question_detail = quest_data['items'][0]\n",
        "            question_title = question_detail.get('title', '')\n",
        "            question_body = question_detail.get('body', '')\n",
        "            num_answers = len(ans_data['items'])\n",
        "\n",
        "            # Store all answers and their upvotes in a structured format\n",
        "            answers_with_upvotes = []\n",
        "            max_upvotes = 0\n",
        "            ianal_answer_max = False\n",
        "            ianal_present = False\n",
        "\n",
        "            for answer in ans_data['items']:\n",
        "                answer_id = answer.get('answer_id')\n",
        "                answer_body = answer.get('body', '').replace('\\n', ' ').replace('\\r', ' ')\n",
        "                upvotes = answer.get('score', 0)\n",
        "                answers_with_upvotes.append(f\"[Answer ID: {answer_id}, Upvotes: {upvotes}] {answer_body}\")\n",
        "\n",
        "                # Determine max upvoted answer\n",
        "                if upvotes > max_upvotes:\n",
        "                    max_upvotes = upvotes\n",
        "                    ianal_answer_max = \"ianal\" in answer_body.lower()\n",
        "\n",
        "                if \"ianal\" in answer_body.lower():\n",
        "                    ianal_present = True\n",
        "\n",
        "            # Determine majority field\n",
        "            if num_answers == 1:\n",
        "                majority = \"NA\"\n",
        "            else:\n",
        "                majority = \"True\" if ianal_present and ianal_answer_max else \"False\"\n",
        "\n",
        "            writer.writerow([question_id, question_title, question_body, num_answers, \" | \".join(answers_with_upvotes), majority])\n",
        "\n",
        "            time.sleep(0.2)\n",
        "\n",
        "        if not data.get('has_more'):\n",
        "            break\n",
        "\n",
        "        page += 1\n",
        "        time.sleep(1)\n",
        "\n",
        "print(f\"Data saved to {OUTPUT_FILE}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNrZGKNPq6UV",
        "outputId": "dec4090e-ce61-4955-aeca-56baf53ea0a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for answers that explicitly contain 'IANAL'...\n",
            "Data saved to ianal_posts_server.csv\n"
          ]
        }
      ]
    }
  ]
}