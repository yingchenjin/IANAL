# -*- coding: utf-8 -*-
"""legal-accuracy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FHpoUT8GHqr4xeogVZ3GMITYxS32Xwox
"""

import pandas as pd
import openai
import time

# Load the dataset (Replace with your file path if running locally)
file_path = "data-ianal.csv"
df = pd.read_csv(file_path)

# Step 1: Filter responses that contain "IANAL"
df_ianal = df[df["answer_body"].astype(str).str.contains("IANAL", case=False, na=False)].copy()

# Select relevant columns (question + answer)
df_ianal_filtered = df_ianal[["question_title", "question_body", "answer_body"]]

# Save the extracted IANAL responses into a new CSV
filtered_csv_path = "filtered_ianal_data.csv"
df_ianal_filtered.to_csv(filtered_csv_path, index=False)
print(f"Filtered IANAL responses saved to: {filtered_csv_path}")

# Step 2: Apply GPT-4 auto-labeling

# OpenAI API Key (Replace with your key)
openai.api_key = "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"

# Function to classify legal accuracy using GPT-4
def label_ianal_response(response):
    prompt = f"""
    The following is a statement from an online forum where a user gives legal advice but says 'IANAL' (I Am Not A Lawyer).

    Statement: "{response}"

    Based on legal principles, software licenses (GPL, MIT, Apache), and general legal knowledge, is this statement legally accurate?

    Return only "1" for Accurate or "0" for Inaccurate.
    """

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "system", "content": "You are a legal expert specializing in software licenses."},
                      {"role": "user", "content": prompt}]
        )
        return int(response["choices"][0]["message"]["content"].strip())

    except Exception as e:
        print(f"Error: {e}")
        return None

# Apply GPT-4 auto-labeling (run GPT-4 for each IANAL response)
df_ianal_filtered["legal_accuracy"] = df_ianal_filtered["answer_body"].apply(label_ianal_response)

# Save the labeled dataset
labeled_csv_path = "ianal_labeled_data.csv"
df_ianal_filtered.to_csv(labeled_csv_path, index=False)
print(f"Labeled IANAL data saved to: {labeled_csv_path}")

import openai
import pandas as pd
import time

# OpenAI API Key (Replace with your actual key)
openai.api_key = "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"

# Function to classify legal accuracy using GPT-4 (Updated for OpenAI v1.0.0+)
def label_ianal_response(response):
    prompt = f"""
    The following is a statement from an online forum where a user gives legal advice but says 'IANAL' (I Am Not A Lawyer).

    Statement: "{response}"

    Based on legal principles, software licenses (GPL, MIT, Apache), and general legal knowledge, is this statement legally accurate?

    Return only "1" for Accurate or "0" for Inaccurate.
    """

    try:
        response = openai.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a legal expert specializing in software licenses."},
                {"role": "user", "content": prompt}
            ]
        )
        return int(response.choices[0].message.content.strip())

    except Exception as e:
        print(f"Error: {e}")
        return None

# Load the filtered IANAL dataset
df_ianal_filtered = pd.read_csv("filtered_ianal_data.csv")

# Apply GPT-4 auto-labeling (run GPT-4 for each IANAL response)
df_ianal_filtered["legal_accuracy"] = df_ianal_filtered["answer_body"].apply(label_ianal_response)

# Save the labeled dataset
df_ianal_filtered.to_csv("ianal_labeled_data.csv", index=False)

print("Labeled IANAL data saved as: ianal_labeled_data.csv")

import openai
openai.api_key = "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"
models = openai.models.list()
print([model.id for model in models.data])

import openai
import pandas as pd
import time

# OpenAI API Key (Replace with your actual key)
openai.api_key = "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"

# Function to classify legal accuracy using GPT-4o
def label_ianal_response(response):
    prompt = f"""
    The following is a statement from an online forum where a user gives legal advice but says 'IANAL' (I Am Not A Lawyer).

    Statement: "{response}"

    Based on legal principles, software licenses (GPL, MIT, Apache), and general legal knowledge, is this statement legally accurate?

    Return only "1" for Accurate or "0" for Inaccurate.
    """

    try:
        response = openai.chat.completions.create(
            model="gpt-4o",  # Use GPT-4o instead of GPT-4
            messages=[
                {"role": "system", "content": "You are a legal expert specializing in software licenses."},
                {"role": "user", "content": prompt}
            ]
        )
        return int(response.choices[0].message.content.strip())

    except Exception as e:
        print(f"Error: {e}")
        return None

# Load the filtered IANAL dataset
df_ianal_filtered = pd.read_csv("filtered_ianal_data.csv")

# Apply GPT-4o auto-labeling (run GPT-4o for each IANAL response)
df_ianal_filtered["legal_accuracy"] = df_ianal_filtered["answer_body"].apply(label_ianal_response)

# Save the labeled dataset
df_ianal_filtered.to_csv("ianal_labeled_data.csv", index=False)

print("Labeled IANAL data saved as: ianal_labeled_data.csv")

!pip install transformers datasets torch scikit-learn

from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments
import pandas as pd
from datasets import Dataset

# Load the LegalBERT model
model_name = "nlpaueb/legal-bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)  # 2 labels: Accurate/Inaccurate

import pandas as pd

# Load the dataset (Replace with your local file path)
file_path = "data-ianal.csv"  # Change this if running locally
df = pd.read_csv(file_path)

# Step 1: Filter responses that contain "IANAL"
df_ianal = df[df["answer_body"].astype(str).str.contains("IANAL", case=False, na=False)].copy()

# Select relevant columns (question + answer)
df_ianal_filtered = df_ianal[["question_title", "question_body", "answer_body"]]

# Save the extracted IANAL responses into a new CSV
filtered_csv_path = "filtered_ianal_data.csv"
df_ianal_filtered.to_csv(filtered_csv_path, index=False)

print(f"Filtered IANAL responses saved to: {filtered_csv_path}")

!pip install faiss-cpu

from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

# Load legal text embedding model
legal_model = SentenceTransformer("sentence-transformers/all-mpnet-base-v2")

# Sample legal references (these can be expanded)
legal_texts = [
    "GPL requires modifications to remain open-source.",
    "MIT license allows unrestricted use with attribution.",
    "Apache allows modifications with proper credit.",
    "Contract law requires agreements to be signed for enforcement.",
    "Employment agreements often include non-disclosure clauses."
]

# Convert legal references to embeddings
legal_embeddings = legal_model.encode(legal_texts)

# Build FAISS index for legal text retrieval
index = faiss.IndexFlatL2(legal_embeddings.shape[1])
index.add(np.array(legal_embeddings))

# Load the filtered IANAL dataset
df_ianal_filtered = pd.read_csv("filtered_ianal_data.csv")

# Function to auto-label based on closest legal text
def legal_match(response):
    query_embedding = legal_model.encode([response])
    _, closest_match = index.search(np.array(query_embedding), 1)
    return 1 if legal_texts[closest_match[0][0]] in response else 0

# Apply retrieval-based labeling
df_ianal_filtered["legal_accuracy"] = df_ianal_filtered["answer_body"].apply(legal_match)

# Save the labeled dataset
df_ianal_filtered.to_csv("ianal_labeled_data.csv", index=False)
print("Labeled IANAL data saved as: ianal_labeled_data.csv")

# Load the labeled dataset
df_labeled = pd.read_csv("ianal_labeled_data.csv")

# Tokenize text
def tokenize_function(examples):
    return tokenizer(examples["answer_body"], padding="max_length", truncation=True)

# Convert to Hugging Face dataset format
dataset = Dataset.from_pandas(df_labeled)
dataset = dataset.map(tokenize_function, batched=True)

# Split into training and test sets
dataset = dataset.train_test_split(test_size=0.2)

training_args = TrainingArguments(
    output_dir="./results",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    num_train_epochs=3,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    logging_dir="./logs",
    logging_steps=10,
)

# Initialize Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset["train"],
    eval_dataset=dataset["test"],
    tokenizer=tokenizer
)

# Train the model
trainer.train()

# Load labeled dataset
df_labeled = pd.read_csv("ianal_labeled_data.csv")

# Rename `legal_accuracy` to `labels` (required by Trainer)
df_labeled = df_labeled.rename(columns={"legal_accuracy": "labels"})

# Ensure labels are integers
df_labeled["labels"] = df_labeled["labels"].astype(int)

# Tokenize input text
def tokenize_function(examples):
    return tokenizer(examples["answer_body"], padding="max_length", truncation=True)

# Convert DataFrame to Hugging Face Dataset format
from datasets import Dataset
dataset = Dataset.from_pandas(df_labeled)
dataset = dataset.map(tokenize_function, batched=True)

# Split into training and test sets
dataset = dataset.train_test_split(test_size=0.2)

# Verify dataset has labels
print(dataset["train"][0])  # Should contain "labels" field

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset["train"],
    eval_dataset=dataset["test"],
    tokenizer=tokenizer  # Ignore deprecation warning for now
)

from transformers import DataCollatorWithPadding

# Define a data collator to handle batch tokenization
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset["train"],
    eval_dataset=dataset["test"],
    data_collator=data_collator  # Replaces tokenizer in Trainer
)

import pandas as pd
import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding
from datasets import Dataset

# Load the LegalBERT model
model_name = "nlpaueb/legal-bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)  # 2 labels: Accurate/Inaccurate

# Step 1: Load Labeled Dataset
df_labeled = pd.read_csv("ianal_labeled_data.csv")

# Rename `legal_accuracy` to `labels` (Trainer requires a 'labels' column)
df_labeled = df_labeled.rename(columns={"legal_accuracy": "labels"})
df_labeled["labels"] = df_labeled["labels"].astype(int)  # Ensure labels are integers

# Step 2: Tokenization Function
def tokenize_function(examples):
    return tokenizer(examples["answer_body"], padding="max_length", truncation=True)

# Step 3: Convert DataFrame to Hugging Face Dataset format
dataset = Dataset.from_pandas(df_labeled)
dataset = dataset.map(tokenize_function, batched=True)

# Step 4: Split into Train/Test Sets
dataset = dataset.train_test_split(test_size=0.2)

# Step 5: Define Training Parameters
training_args = TrainingArguments(
    output_dir="./results",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    num_train_epochs=3,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    logging_dir="./logs",
    logging_steps=10,
)

# Step 6: Define a Data Collator (Handles Padding Dynamically)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

# Step 7: Initialize Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset["train"],
    eval_dataset=dataset["test"],
    data_collator=data_collator  # Use the correct data collator
)

# Step 8: Train the Model
trainer.train()

# Step 9: Evaluate Model Performance
metrics = trainer.evaluate()
print("Evaluation Results:", metrics)

# Step 10: Save Trained Model
model.save_pretrained("./legalbert_ianal_model")
tokenizer.save_pretrained("./legalbert_ianal_model")

print("Model saved successfully!")

import torch

# Check if CUDA (GPU) is available, otherwise use CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)  # Move model to the correct device

# Function to predict the legal accuracy of an IANAL response
def predict_ianal_response(response):
    inputs = tokenizer(response, return_tensors="pt", padding=True, truncation=True).to(device)  # Move inputs to same device
    outputs = model(**inputs)
    prediction = outputs.logits.argmax().item()
    return "Accurate" if prediction == 1 else "Inaccurate"

# Example Usage
response = "You can use GPL in proprietary software."
print("Predicted Label:", predict_ianal_response(response))

!pip install PyPDF2

import pandas as pd
from PyPDF2 import PdfReader
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
import joblib

# Step 1: Extract Text from Official License PDFs & Google Open Source Casebook
pdf_files = [
    "/content/Apache License, Version 2.0 – Open Source Initiative.pdf",
    "/content/Apache Software License, version 1.1 – Open Source Initiative.pdf",
    "/content/GNU Affero General Public License version 3 – Open Source Initiative.pdf",
    "/content/GNU General Public License version 2 – Open Source Initiative.pdf",
    "/content/GNU General Public License version 3 – Open Source Initiative.pdf",
    "/content/GNU Lesser General Public License version 2.1 – Open Source Initiative.pdf"
]

# Read and extract text from PDFs
license_texts = {}
for pdf_file in pdf_files:
    reader = PdfReader(pdf_file)
    text = "\n".join([page.extract_text() for page in reader.pages if page.extract_text()])
    license_texts[pdf_file] = text

# Combine all license texts
license_corpus = list(license_texts.values())

# Step 2: Load Forum Answers CSV
forum_answers_file = "/content/data-ianal.csv"
forum_data = pd.read_csv(forum_answers_file)

# Ensure correct column names (adjust if needed)
expected_columns = ['post_type', 'post_id', 'creation_date', 'question_id', 'question_title', 'question_body', 'answer_body', 'Category']
forum_data = forum_data[expected_columns]

# Step 3: Compute Similarity Between Answers and Official License Texts
vectorizer = TfidfVectorizer()
doc_vectors = vectorizer.fit_transform(license_corpus)  # License texts
answer_vectors = vectorizer.transform(forum_data['answer_body'].fillna(''))  # Forum answers

# Compute cosine similarity
similarities = cosine_similarity(answer_vectors, doc_vectors)

# Step 4: Assign Labels Based on Similarity Score
def assign_label(sim_score):
    if max(sim_score) >= 0.60:
        return "Accurate"
    elif max(sim_score) <= 0.40:
        return "Inaccurate"
    else:
        return "Needs Review"

# Apply labeling function
forum_data["Accuracy_Label"] = [assign_label(sim) for sim in similarities]

# Step 5: Encode Labels for Model Training
label_mapping = {"Accurate": 2, "Needs Review": 1, "Inaccurate": 0}  # Explicit label mapping
forum_data["Label_Encoded"] = forum_data["Accuracy_Label"].map(label_mapping)

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(answer_vectors, forum_data["Label_Encoded"], test_size=0.2, random_state=42)

# Train Random Forest Model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Predict on test set
y_pred = model.predict(X_test)

# Print Evaluation Metrics
print("Classification Report:\n", classification_report(y_test, y_pred))

# Save the Labeled Data and Model for Download
forum_data.to_csv("/content/labeled_forum_answers.csv", index=False)
joblib.dump(model, "/content/license_accuracy_model.pkl")

print("\nProcessing complete! Download results:")
print("Labeled Data: /content/labeled_forum_answers.csv")
print("Trained Model: /content/license_accuracy_model.pkl")